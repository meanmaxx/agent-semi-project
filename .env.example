# ===========================================
# vLLM Tool-using Agent Service Configuration
# ===========================================

# ----- vLLM Configuration -----
# Model to use (must support tool calling)
VLLM_MODEL=Qwen/Qwen2.5-7B-Instruct

# vLLM server URL (for backend to connect)
VLLM_BASE_URL=http://localhost:8000

# vLLM server port
VLLM_PORT=8000

# Tool call parser (hermes, mistral, etc.)
TOOL_CALL_PARSER=hermes

# GPU memory utilization (0.0 - 1.0)
GPU_MEMORY_UTILIZATION=0.9

# Hugging Face token (required for some models)
HF_TOKEN=

# ----- Backend Configuration -----
# Backend server port
BACKEND_PORT=8080

# Allowed CORS origins (comma-separated)
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000

# Log level (debug, info, warning, error)
LOG_LEVEL=info

# ----- Frontend Configuration -----
# Frontend server port
FRONTEND_PORT=5173

# API URL for frontend to connect to backend
VITE_API_URL=http://localhost:8080

# ----- Development -----
# Enable debug mode
DEBUG=false
